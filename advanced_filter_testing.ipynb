{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "tensorflow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import imutils \n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "tf.__version__\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "import skimage.feature\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#check if tensorflow gpu is being used\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Frame Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videos to choose from\n",
    "NeedleViz_path1 = 'Data/edited data/102622_Water.mp4'\n",
    "NeedleViz_path2 = 'Data/edited data/102822_Water.mp4'\n",
    "NeedleViz_oilAndLatex = 'Data/edited data/oil and latex/capture_5_2022-11-12T16-56-03.mp4'\n",
    "NeedleViz_gelAndLatex = 'Data/edited data/ultrasound gel and latex/capture_4_2022-11-12T17-33-19.mp4'\n",
    "NeedleViz_clarius1 = 'Data/edited data/clarius_FinalPrototype_needlejustWater.mp4'\n",
    "NeedleViz_clarius2 = 'Data/edited data/clarius_FinalPrototype_needlejustWater2.mp4'\n",
    "NeedleViz_clarius3 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid.mp4'\n",
    "NeedleViz_clarius4 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid2.mp4'\n",
    "NeedleViz_clarius5 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid3.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameList = []\n",
    "\n",
    "vc = cv2.VideoCapture(NeedleViz_clarius1)\n",
    "\n",
    "if (vc.isOpened()== False): \n",
    "  print(\"Error opening video  file\")\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    if rval == True:\n",
    "      frameList.append(frame)\n",
    "        \n",
    "    #Break out of loop if video is done\n",
    "    else:\n",
    "        break  \n",
    "\n",
    "vc.release() #Release the video capture object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = frameList[30]\n",
    "image_refined = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROI FRAME EXTRACTION ###\n",
    "\n",
    "size = (440, 440)\n",
    "\n",
    "#Initial Frame preprocessing\n",
    "resized_frame = cv2.resize(image, size)\n",
    "resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(resized_frame)\n",
    "\n",
    "#Achieving desired region of interest within Raw Frame\n",
    "row_start = 140 #previously 94\n",
    "row_end = 348\n",
    "col_start = 195 #previously 166\n",
    "col_end = 235 #previously 275\n",
    "\n",
    "ROI_frame = resized_frame[row_start:row_end, col_start:col_end] #old one was [94:348, 166:275]\n",
    "ROI_image = np.zeros_like(resized_frame)\n",
    "x = row_start \n",
    "y = col_start \n",
    "for i in range(0, row_end-row_start):\n",
    "    for j in range(0, col_end-col_start):\n",
    "        if ROI_frame[i][j] != 0:\n",
    "            ROI_image[x + i, y + j] = ROI_frame[i, j]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ROI_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLURRING AND THRESHOLDING ###\n",
    "\n",
    "thresh = cv2.threshold(ROI_image, 90, 255, cv2.THRESH_BINARY)[1]\n",
    "plt.figure()\n",
    "plt.imshow(thresh)\n",
    "\n",
    "# adapt_thresh = cv2.adaptiveThreshold(thresh, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(adapt_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MORPHOLOGICAL OPERATIONS ###\n",
    "dilate = cv2.dilate(thresh, None, iterations=2)\n",
    "erode = cv2.erode(dilate, None, iterations=2)\n",
    "dilate_2 = cv2.dilate(erode, None, iterations=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(dilate_2)\n",
    "\n",
    "#Creating skeleton -> https://medium.com/analytics-vidhya/skeletonization-in-python-using-opencv-b7fa16867331 \n",
    "\n",
    "skel_image = thresh.copy()\n",
    "\n",
    "# Step 1: Create an empty skeleton\n",
    "size = np.size(skel_image)\n",
    "skel = np.zeros(skel_image.shape, np.uint8)\n",
    "\n",
    "# Get a Cross Shaped Kernel\n",
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "\n",
    "count = 0\n",
    "# Repeat steps 2-4\n",
    "while True:\n",
    "    #Step 2: Open the image\n",
    "    open = cv2.morphologyEx(skel_image, cv2.MORPH_OPEN, element)\n",
    "    #Step 3: Substract open from the original image\n",
    "    temp = cv2.subtract(skel_image, open)\n",
    "    #Step 4: Erode the original image and refine the skeleton\n",
    "    eroded = cv2.erode(skel_image, element)\n",
    "    skel = cv2.bitwise_or(skel_image,temp)\n",
    "    skel_image = eroded.copy()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(skel_image)\n",
    "    count += 1\n",
    "    # Step 5: If there are no white pixels left ie.. the image has been completely eroded, quit the loop\n",
    "    if count == 3:\n",
    "        break\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(skel_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CANNY EDGE DETECTION ###\n",
    "canny = cv2.Canny(skel_image, 73,200)\n",
    "\n",
    "plt.imshow(canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = resized_frame.copy()\n",
    "detect_bbox(canny,bbox)\n",
    "plt.imshow(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm based on Paper: https://ris.utwente.nl/ws/portalfiles/portal/268816902/elk_28_5_37_1912_181.pdf \n",
    "\n",
    "#Raw Image\n",
    "raw_image = ROI_image.copy()\n",
    "# plt.figure()\n",
    "# plt.imshow(raw_image)\n",
    "\n",
    "#Gabor Filter at angle 0\n",
    "\n",
    "gabor_filter = cv2.getGaborKernel((3,3), sigma=0.95, theta=0, lambd=5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "# gabor_filter = cv2.getGaborKernel((3,3), sigma=10, theta=0, lambd=30, gamma=0.25, psi=0, ktype=cv2.CV_32F)\n",
    "# plt.figure()\n",
    "# plt.imshow(gabor_filter)\n",
    "gabor_output = cv2.filter2D(raw_image, -1, gabor_filter)\n",
    "# plt.figure()\n",
    "# plt.imshow(gabor_output)\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(131)\n",
    "plt.axis('off')\n",
    "plt.title('image')\n",
    "plt.imshow(raw_image, cmap='gray')\n",
    "plt.subplot(132)\n",
    "plt.title('kernel')\n",
    "plt.imshow(gabor_filter, cmap='gray')\n",
    "plt.subplot(133)\n",
    "plt.axis('off')\n",
    "plt.title('filtered')\n",
    "plt.imshow(gabor_output, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Binarized image is divided into grids for needle axis localization.\n",
    "# - Median filter\n",
    "median_filter = cv2.medianBlur(gabor_output, 7)\n",
    "plt.figure()\n",
    "plt.imshow(median_filter)\n",
    "# - automatic thresholding\n",
    "threshold = cv2.threshold(median_filter, 250, 255, cv2.THRESH_BINARY)[1]\n",
    "# - morphological operations\n",
    "element = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "eroded = cv2.erode(threshold, element)\n",
    "dilated = cv2.dilate(eroded, element)\n",
    "plt.figure()\n",
    "plt.imshow(dilated)\n",
    "\n",
    "#needle tip estimation\n",
    "\n",
    "\n",
    "# Connected components\n",
    "\n",
    "# largest connected component is chosen as the needle\n",
    "\n",
    "#  Needle axis is localized by applying RANSAC line fitting to each grid\n",
    "\n",
    "# The needle tip is estimated using probability mapping method\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(dilated, rho=6, theta=np.pi / 60, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "\n",
    "overlay_image = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "houghline = overlay_image.copy()\n",
    "\n",
    "for line in lines:\n",
    "    # print(line)\n",
    "    # print(line[0][0])\n",
    "    # Start coordinate, here (0, 0)\n",
    "    # represents the top left corner of image\n",
    "    start_point = (line[0][0], line[0][1])\n",
    "    \n",
    "    # End coordinate, here (250, 250)\n",
    "    # represents the bottom right corner of image\n",
    "    end_point = (line[0][2], line[0][3])\n",
    "    \n",
    "    # Green color in BGR\n",
    "    color = (0, 255, 0)\n",
    "    \n",
    "    # Line thickness of 9 px\n",
    "    thickness = 2\n",
    "    \n",
    "    # Using cv2.line() method\n",
    "    # Draw a diagonal green line with thickness of 9 px\n",
    "    cv2.line(houghline, start_point, end_point, color, thickness)\n",
    "\n",
    "plt.imshow(houghline)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('clarius')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9962539669d5dbe9522d46f218cca01fd3b7ad23018b1c5959dcfe17c72706ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
