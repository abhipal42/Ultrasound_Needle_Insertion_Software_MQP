{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "tensorflow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import imutils \n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "tf.__version__\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "#check if tensorflow gpu is being used\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img,imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        \n",
    "        #Debugging statements\n",
    "        # if area > 1:\n",
    "        #     print(\"Area of contour is: {}\".format(area))\n",
    "        \n",
    "        areaMin = 60\n",
    "        areaMax = 250\n",
    "        if area > areaMin and area < areaMax:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            # print(len(approx))\n",
    "            x , y , w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x , y ), (x + w , y + h ), (0, 255, 0), 5)\n",
    "\n",
    "            #compute center of contour\n",
    "            # M = cv2.moments(cnt)\n",
    "        \n",
    "            # if M[\"m00\"] != 0:\n",
    "            #     cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            #     cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            # else:\n",
    "            # # set values as what you need in the situation\n",
    "            #     cX, cY = 0, 0\n",
    "\n",
    "\t        # # draw the contour and center of the shape on the image\n",
    "            # cv2.circle(imgContour, (cX, cY), 7, (255, 255, 255), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videos to choose from\n",
    "NeedleViz_path1 = 'Data/edited data/102622_Water.mp4'\n",
    "NeedleViz_path2 = 'Data/edited data/102822_Water.mp4'\n",
    "NeedleViz_oilAndLatex = 'Data/edited data/oil and latex/capture_5_2022-11-12T16-56-03.mp4'\n",
    "NeedleViz_gelAndLatex = 'Data/edited data/ultrasound gel and latex/capture_4_2022-11-12T17-33-19.mp4'\n",
    "\n",
    "#control playback speed\n",
    "frame_rate = 30\n",
    "\n",
    "#trajectory path length\n",
    "trajectory_number = 3\n",
    "pts = deque(maxlen=trajectory_number)\n",
    "\n",
    "# vc = cv2.VideoCapture(0) #opens camera\n",
    "vc = cv2.VideoCapture(NeedleViz_path2)\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2() #pretty good: (100,200)\n",
    "knn = cv2.createBackgroundSubtractorKNN(detectShadows=False)\n",
    "\n",
    "# prev_frame_time = 0\n",
    "# new_frame_time = 0\n",
    "# average_fps_list = []\n",
    "\n",
    "frameWidth = 440\n",
    "frameHeight = 440\n",
    "vc.set(3, frameWidth)\n",
    "vc.set(4, frameHeight)\n",
    "\n",
    "size = (frameWidth, frameHeight)\n",
    "\n",
    "#Preparing to create output videos\n",
    "# result = cv2.VideoWriter('Outputs/V1_videoUpdated.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, size)\n",
    "image_lst = []\n",
    "\n",
    "if (vc.isOpened()== False): \n",
    "  print(\"Error opening video  file\")\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    if rval == True:\n",
    "        #Insert Code Here\n",
    "        \n",
    "\n",
    "\n",
    "        #Initial Frame preprocessing\n",
    "        resized_frame = cv2.resize(frame, (frameWidth,frameHeight))\n",
    "        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "        #Achieving desired region of interest within Raw Frame\n",
    "        ROI_frame = resized_frame[94:348, 166:275]\n",
    "         # ROI_frame = resized_frame[col_initial:col_final,row_initial:row_final]\n",
    "        blank_img = np.zeros_like(resized_frame)\n",
    "        imgContour = blank_img.copy()\n",
    "\n",
    "        x = 94 #initial column number\n",
    "        y = 166 #initial row number\n",
    "        for i in range(0, 254):\n",
    "          for j in range(0, 109):\n",
    "\n",
    "            if ROI_frame[i][j] != 0:\n",
    "              blank_img[x + i, y + j] = ROI_frame[i, j] \n",
    "\n",
    "        fgmask = fgbg.apply(blank_img)\n",
    "\n",
    "        #Applying Basic Filters\n",
    "        #############################################################\n",
    "        imgBlur = cv2.GaussianBlur(blank_img,(7,7), 1)\n",
    "        # erode = cv2.erode(imgBlur, None, iterations=2)\n",
    "        # dilate = cv2.dilate(erode, None, iterations=2)\n",
    "        gaussian = 255*imgBlur+100\n",
    "        # median = cv2.medianBlur(contrast_imgBlur, 7)\n",
    "        ##############################################################\n",
    "\n",
    "        #Applying Background Subtraction (detecting regions of motion within frame)\n",
    "        fgmaskV2 = fgbg.apply(imgBlur)\n",
    "\n",
    "\n",
    "        #Applying Contour detection (detectiong only regions past certain size)\n",
    "        # imgCanny_initial = cv2.Canny(imgBlur, 155, 191)\n",
    "        getContours(fgmaskV2,imgContour)\n",
    "\n",
    "        #Applying trajectory/velocity tracking (detecting orientation of motion and see how fast region is moving) --> CURRENTLY NOT WORKING\n",
    "\n",
    "        trajectory_frame = fgmaskV2.copy()\n",
    "        # find contours in the mask and initialize the current\n",
    "\t      # (x, y) center of the ball\n",
    "        cnts = cv2.findContours(fgmaskV2.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        center = None\n",
    "\n",
    "          \n",
    "        # only proceed if at least one contour was found\n",
    "        if len(cnts) > 0:\n",
    "          # find the largest contour in the mask, then use\n",
    "          # it to compute the minimum enclosing circle and\n",
    "          # centroid\n",
    "          c = max(cnts, key=cv2.contourArea)\n",
    "          ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "          M = cv2.moments(c)\n",
    "          \n",
    "          if M[\"m00\"] != 0:\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "          else:\n",
    "            center = (0,0)\n",
    "      \n",
    "          # only proceed if the radius meets a minimum size\n",
    "          if radius > 10:\n",
    "            # draw the circle and centroid on the frame,\n",
    "            # then update the list of tracked points\n",
    "            cv2.circle(trajectory_frame, (int(x), int(y)), int(radius),\n",
    "              (0, 255, 255), 2)\n",
    "            cv2.circle(trajectory_frame, center, 5, (0, 0, 255), -1)\n",
    "        \n",
    "        # update the points queue\n",
    "        pts.appendleft(center)\n",
    "\n",
    "\n",
    "          # loop over the set of tracked points\n",
    "        for i in range(1, len(pts)):\n",
    "          \n",
    "          # if either of the tracked points are None, ignore\n",
    "          # them\n",
    "          if pts[i - 1] is None or pts[i] is None:\n",
    "              continue\n",
    "      \n",
    "          # otherwise, compute the thickness of the line and\n",
    "          # draw the connecting lines\n",
    "          thickness = int(np.sqrt(trajectory_number / float(i + 1)) * 2.5)\n",
    "          cv2.line(trajectory_frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "        \n",
    "        \n",
    "        #Overlaying segmentations onto B-mode image\n",
    "        #############################################################################################\n",
    "        fgmaskV2_color = cv2.applyColorMap(imgContour, cv2.COLORMAP_INFERNO)\n",
    "        resized_frame_revert = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2RGB)\n",
    "        overlay = cv2.addWeighted(resized_frame_revert, 0.5, fgmaskV2_color, 0.5, 1.0)\n",
    "        cv2.imshow(\"Bmode Overlay\", overlay)\n",
    "        ###########################################################################################\n",
    "\n",
    "        # Debugging Statements\n",
    "        cv2.imshow('normal frame', resized_frame)\n",
    "        # cv2.imshow('FGmask', fgmask)\n",
    "        # cv2.imshow('Basic Filters', imgBlur)\n",
    "        # cv2.imshow('Canny', imgCanny_initial)\n",
    "        # cv2.imshow('FGmaskV2', fgmaskV2)\n",
    "        # cv2.imshow('Contour', imgContour)\n",
    "        # cv2.imshow('trajectory', trajectory_frame)\n",
    "        # print(\"raw image shape = {}\".format(resized_frame.shape))\n",
    "        # print(\"segmented image shape = {}\".format(fgmaskV2_color.shape))\n",
    "        # print(\"raw image shape (reverted)= {}\".format(resized_frame_revert.shape))\n",
    "        \n",
    "        #Saving comparison frames as gif \n",
    "        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2BGR)\n",
    "        overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "        stack = np.hstack((resized_frame, overlay))\n",
    "        cv2.imshow(\"stacked\", stack)\n",
    "        # result.write(stack)\n",
    "        image_lst.append(stack)\n",
    "\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(frame_rate) & 0xFF == ord('q'): #original waitkey is 25\n",
    "            break\n",
    "    \n",
    "    #Break out of loop if video is done\n",
    "    else:\n",
    "        break  \n",
    "\n",
    "vc.release() #Release the video capture object\n",
    "\n",
    "# Close window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('Outputs/V1_video.gif', image_lst, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('clarius')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9962539669d5dbe9522d46f218cca01fd3b7ad23018b1c5959dcfe17c72706ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
