{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "tensorflow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time \n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "tf.__version__\n",
    "import glob\n",
    "\n",
    "#check if tensorflow gpu is being used\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img,imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        areaMin = cv2.getTrackbarPos(\"Area\", \"Parameters\")\n",
    "        if area > areaMin:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            # print(len(approx))\n",
    "            x , y , w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x , y ), (x + w , y + h ), (0, 255, 0), 5)\n",
    "\n",
    "            # cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x + w + 20, y + 20), cv2.FONT_HERSHEY_COMPLEX, .7,\n",
    "            #             (0, 255, 0), 2)\n",
    "            # cv2.putText(imgContour, \"Area: \" + str(int(area)), (x + w + 20, y + 45), cv2.FONT_HERSHEY_COMPLEX, 0.7,\n",
    "            #             (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realtime Segmentation with Dice Score and Bounding Box Detection\n",
    "\n",
    "#Reference for bbox(Github): https://github.com/murtazahassan/OpenCV-Python-Tutorials-and-Projects/blob/master/Intermediate/RealTime_Shape_Detection_Contours.py \n",
    "#Reference for bbox (Video): https://www.youtube.com/watch?v=Fchzk1lDt7Q \n",
    "\n",
    "#Reference for realtime segmentation: https://anirudhtopiwala.com/my-robots/skin-segmentation-using-deep-learning/\n",
    "#Github Code for realtime segmentation: https://github.com/anirudhtopiwala/abd-skin-segmentation/blob/master/Real%20Time%20Skin%20Segmentation/UNET-live.py \n",
    "#playing video on openCV: https://www.geeksforgeeks.org/python-play-a-video-using-opencv/ \n",
    "#adding FPS for openCV: https://www.geeksforgeeks.org/python-displaying-real-time-fps-at-which-webcam-video-file-is-processed-using-opencv/ \n",
    "\n",
    "#videos to choose from\n",
    "NeedleViz_path1 = 'Data/edited data/102622_Water.mp4'\n",
    "NeedleViz_path2 = 'Data/edited data/102822_Water.mp4'\n",
    "\n",
    "#control playback speed\n",
    "frame_rate = 25\n",
    "\n",
    "# vc = cv2.VideoCapture(0) #opens camera\n",
    "vc = cv2.VideoCapture(NeedleViz_path1)\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "average_fps_list = []\n",
    "\n",
    "frameWidth = 440\n",
    "frameHeight = 440\n",
    "vc.set(3, frameWidth)\n",
    "vc.set(4, frameHeight)\n",
    "\n",
    "def empty(a):\n",
    "  pass\n",
    "\n",
    "cv2.namedWindow(\"Parameters\")\n",
    "cv2.resizeWindow(\"Parameters\",640,240)\n",
    "cv2.createTrackbar(\"Threshold1\",\"Parameters\",155,255,empty)\n",
    "cv2.createTrackbar(\"Threshold2\",\"Parameters\",191,255,empty)\n",
    "cv2.createTrackbar(\"Threshold3\",\"Parameters\",0,13,empty)\n",
    "cv2.createTrackbar(\"Threshold4\",\"Parameters\",0,13,empty)\n",
    "cv2.createTrackbar(\"Area\",\"Parameters\",5000,30000,empty)\n",
    "\n",
    "\n",
    "#Reference: https://stackoverflow.com/questions/39308030/how-do-i-increase-the-contrast-of-an-image-in-python-opencv\n",
    "cv2.createTrackbar(\"alpha\",\"Parameters\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"beta\",\"Parameters\", 197, 255, empty)\n",
    "\n",
    "\n",
    "if (vc.isOpened()== False): \n",
    "  print(\"Error opening video  file\")\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    if rval == True:\n",
    "      #Insert Code Here\n",
    "\n",
    "      new_frame_time = time.time()\n",
    "      fps = 1/(new_frame_time-prev_frame_time)\n",
    "      prev_frame_time = new_frame_time\n",
    "\n",
    "      fps = int(fps)\n",
    "      average_fps_list.append(fps)\n",
    "\n",
    "      ## Initial Image Processing ##\n",
    "  \n",
    "      raw_image_1 = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "      raw_image = cv2.resize(raw_image_1, (frameWidth,frameHeight))\n",
    "      # raw_image = raw_image_1\n",
    "      # print(raw_image.shape)\n",
    "      #Converting float64 to uint8 for proper processing in opencv\n",
    "      updated_maskV2 = raw_image.astype(np.uint8)\n",
    "      imgContour = raw_image.copy() #copy desired frame (normal frame or predicted mask) to have contour and bboxes layed over for realtime display\n",
    "      \n",
    "\n",
    "      #smoothens the image \n",
    "      imgBlur = cv2.GaussianBlur(updated_maskV2,(7,7), 1)\n",
    "\n",
    "\n",
    "      #Adjusting contrast levels (issue was that the original image was so dim it could not be seen as mentioned during a warning)\n",
    "      alpha = cv2.getTrackbarPos(\"alpha\", \"Parameters\")\n",
    "      beta = cv2.getTrackbarPos(\"beta\", \"Parameters\")\n",
    "      contrast_imageBlur = alpha*imgBlur+beta\n",
    "\n",
    "      #detects canny edges\n",
    "      threshold1 = cv2.getTrackbarPos(\"Threshold1\", \"Parameters\")\n",
    "      threshold2 = cv2.getTrackbarPos(\"Threshold2\", \"Parameters\")\n",
    "      imgCanny_initial = cv2.Canny(contrast_imageBlur, threshold1, threshold2)\n",
    "\n",
    "      #Detect vertical lines (reference: https://www.youtube.com/watch?v=veoz_46gOkc&ab_channel=ProgrammingEpitome)\n",
    "      threshold3 = cv2.getTrackbarPos(\"Threshold3\", \"Parameters\")\n",
    "      threshold4 = cv2.getTrackbarPos(\"Threshold4\", \"Parameters\")\n",
    "      kernel_vertical = np.ones((threshold3,threshold4), np.uint8)\n",
    "      imgCanny = cv2.erode(imgCanny_initial, kernel_vertical, iterations=1)\n",
    "\n",
    "\n",
    "      #dilation to further remove any noise generated by canny detection \n",
    "      kernel = np.ones((5, 5))\n",
    "      imgDil = cv2.dilate(imgCanny_initial, kernel, iterations=1)\n",
    "      getContours(imgDil,imgContour)\n",
    "      \n",
    "      \n",
    "      # putting the FPS count and dice score evalution on the preview frame\n",
    "      cv2.putText(imgCanny_initial, 'FPS: {}'.format(str(fps)), (7, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "      # cv2.putText(imgCanny, 'DiceScore: {}'.format(str(realtime_dice)), (180, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "      \n",
    "\n",
    "      # SEPERATE WINDOWS #\n",
    "      # cv2.imshow(\"preview1\", contrast_imageBlur) #originally preds_resized\n",
    "      # cv2.imshow(\"preview2\", imgCanny) #originally preds_resized\n",
    "      # cv2.imshow(\"preview3\", imgContour)\n",
    "      # cv2.imshow(\"normal\",raw_image)\n",
    "      \n",
    "      # COMBINED WINDOWS #\n",
    "      imgStack = stackImages(0.8,([raw_image,contrast_imageBlur],[imgCanny_initial,imgContour]))\n",
    "      cv2.imshow(\"stacked\", imgStack)\n",
    "\n",
    "\n",
    "      # Press Q on keyboard to  exit\n",
    "      if cv2.waitKey(frame_rate) & 0xFF == ord('q'): #original waitkey is 25\n",
    "          break\n",
    "    \n",
    "    #Break out of loop if video is done\n",
    "    else:\n",
    "        break  \n",
    "\n",
    "vc.release() #Release the video capture object\n",
    "\n",
    "# Close windows\n",
    "\n",
    "# cv2.destroyWindow(\"normal\")\n",
    "# cv2.destroyWindow(\"preview1\")\n",
    "# cv2.destroyWindow(\"preview2\")\n",
    "# cv2.destroyWindow(\"preview3\")\n",
    "\n",
    "cv2.destroyWindow(\"stacked\")\n",
    "\n",
    "\n",
    "cv2.destroyWindow(\"Parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('clarius')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9962539669d5dbe9522d46f218cca01fd3b7ad23018b1c5959dcfe17c72706ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
