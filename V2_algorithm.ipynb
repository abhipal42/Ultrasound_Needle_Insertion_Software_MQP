{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "tensorflow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import imutils \n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "tf.__version__\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "#check if tensorflow gpu is being used\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img,imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        \n",
    "        #Debugging statements\n",
    "        # if area > 1:\n",
    "        #     print(\"Area of contour is: {}\".format(area))\n",
    "        \n",
    "        areaMin = 60\n",
    "        areaMax = 250\n",
    "        if area > areaMin and area < areaMax:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            # print(len(approx))\n",
    "            x , y , w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x , y ), (x + w , y + h ), (0, 255, 0), 5)\n",
    "\n",
    "            #compute center of contour\n",
    "            # M = cv2.moments(cnt)\n",
    "        \n",
    "            # if M[\"m00\"] != 0:\n",
    "            #     cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            #     cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            # else:\n",
    "            # # set values as what you need in the situation\n",
    "            #     cX, cY = 0, 0\n",
    "\n",
    "\t        # # draw the contour and center of the shape on the image\n",
    "            # cv2.circle(imgContour, (cX, cY), 7, (255, 255, 255), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\video\\src\\lkpyramid.cpp:1394: error: (-215:Assertion failed) prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size() in function 'cv::`anonymous-namespace'::SparsePyrLKOpticalFlowImpl::calc'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 111\u001b[0m\n\u001b[0;32m    108\u001b[0m p0 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mgoodFeaturesToTrack(imgContour, mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfeature_params)\n\u001b[0;32m    110\u001b[0m \u001b[39m# calculate optical flow\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m p1, st, err \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalcOpticalFlowPyrLK(old_gray, imgContour, p0, \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlk_params)\n\u001b[0;32m    113\u001b[0m \u001b[39m# Select good points\u001b[39;00m\n\u001b[0;32m    114\u001b[0m good_new \u001b[39m=\u001b[39m p1[st \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\video\\src\\lkpyramid.cpp:1394: error: (-215:Assertion failed) prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size() in function 'cv::`anonymous-namespace'::SparsePyrLKOpticalFlowImpl::calc'\n"
     ]
    }
   ],
   "source": [
    "#videos to choose from\n",
    "NeedleViz_path1 = 'Data/edited data/102622_Water.mp4'\n",
    "NeedleViz_path2 = 'Data/edited data/102822_Water.mp4'\n",
    "NeedleViz_oilAndLatex = 'Data/edited data/oil and latex/capture_5_2022-11-12T16-56-03.mp4'\n",
    "NeedleViz_gelAndLatex = 'Data/edited data/ultrasound gel and latex/capture_4_2022-11-12T17-33-19.mp4'\n",
    "\n",
    "#control playback speed\n",
    "frame_rate = 30\n",
    "\n",
    "#trajectory path length\n",
    "trajectory_number = 3\n",
    "pts = deque(maxlen=trajectory_number)\n",
    "\n",
    "# vc = cv2.VideoCapture(0) #opens camera\n",
    "vc = cv2.VideoCapture(NeedleViz_oilAndLatex)\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2() #pretty good: (100,200)\n",
    "knn = cv2.createBackgroundSubtractorKNN(detectShadows=False)\n",
    "\n",
    "# prev_frame_time = 0\n",
    "# new_frame_time = 0\n",
    "# average_fps_list = []\n",
    "\n",
    "frameWidth = 440\n",
    "frameHeight = 440\n",
    "vc.set(3, frameWidth)\n",
    "vc.set(4, frameHeight)\n",
    "\n",
    "size = (frameWidth, frameHeight)\n",
    "\n",
    "#Preparing to create output videos\n",
    "# result = cv2.VideoWriter('Outputs/V1_videoUpdated.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, size)\n",
    "image_lst = []\n",
    "\n",
    "\n",
    "if (vc.isOpened()== False): \n",
    "  print(\"Error opening video  file\")\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    if rval == True:\n",
    "        #Insert Code Here\n",
    "        \n",
    "\n",
    "\n",
    "        #Initial Frame preprocessing\n",
    "        resized_frame = cv2.resize(frame, (frameWidth,frameHeight))\n",
    "        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "        #Achieving desired region of interest within Raw Frame\n",
    "        ROI_frame = resized_frame[94:348, 166:275]\n",
    "         # ROI_frame = resized_frame[col_initial:col_final,row_initial:row_final]\n",
    "        blank_img = np.zeros_like(resized_frame)\n",
    "        imgContour = blank_img.copy()\n",
    "\n",
    "        x = 94 #initial column number\n",
    "        y = 166 #initial row number\n",
    "        for i in range(0, 254):\n",
    "          for j in range(0, 109):\n",
    "\n",
    "            if ROI_frame[i][j] != 0:\n",
    "              blank_img[x + i, y + j] = ROI_frame[i, j] \n",
    "\n",
    "        fgmask = fgbg.apply(blank_img)\n",
    "\n",
    "        #Applying Basic Filters\n",
    "        #############################################################\n",
    "        imgBlur = cv2.GaussianBlur(blank_img,(7,7), 1)\n",
    "        # erode = cv2.erode(imgBlur, None, iterations=2)\n",
    "        # dilate = cv2.dilate(erode, None, iterations=2)\n",
    "        gaussian = 255*imgBlur+100\n",
    "        # median = cv2.medianBlur(contrast_imgBlur, 7)\n",
    "        ##############################################################\n",
    "\n",
    "        #Applying Background Subtraction (detecting regions of motion within frame)\n",
    "        fgmaskV2 = fgbg.apply(imgBlur)\n",
    "\n",
    "        maskV2 = cv2.erode(fgmaskV2, None, iterations=2) \n",
    "        maskV2 = cv2.dilate(maskV2, None, iterations=2)\n",
    "\n",
    "        #Applying Contour detection (detectiong only regions past certain size)\n",
    "        # imgCanny_initial = cv2.Canny(imgBlur, 155, 191)\n",
    "        getContours(fgmaskV2,imgContour)\n",
    "        # getContours(maskV2,imgContour)\n",
    "\n",
    "        #Applying trajectory/velocity tracking (detecting orientation of motion and see how fast region is moving) --> CURRENTLY NOT WORKING\n",
    "        \n",
    "        #Overlaying segmentations onto B-mode image\n",
    "        #############################################################################################\n",
    "        fgmaskV2_color = cv2.applyColorMap(imgContour, cv2.COLORMAP_INFERNO)\n",
    "        resized_frame_revert = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2RGB)\n",
    "        overlay = cv2.addWeighted(resized_frame_revert, 0.5, fgmaskV2_color, 0.5, 1.0)\n",
    "        # cv2.imshow(\"Bmode Overlay\", overlay)\n",
    "        ###########################################################################################\n",
    "\n",
    "        # Debugging Statements\n",
    "        cv2.imshow('normal frame', resized_frame)\n",
    "        # cv2.imshow('FGmask', fgmask)\n",
    "        # cv2.imshow('Basic Filters', imgBlur)\n",
    "        # cv2.imshow('Canny', imgCanny_initial)\n",
    "        # cv2.imshow('FGmaskV2', fgmaskV2)\n",
    "        # cv2.imshow('FGmaskV2_withfilters', maskV2)\n",
    "        cv2.imshow('Contour', imgContour)\n",
    "        # cv2.imshow('trajectory', trajectory_frame)\n",
    "        # print(\"raw image shape = {}\".format(resized_frame.shape))\n",
    "        # print(\"segmented image shape = {}\".format(fgmaskV2_color.shape))\n",
    "        # print(\"raw image shape (reverted)= {}\".format(resized_frame_revert.shape))\n",
    "        \n",
    "        #Saving comparison frames as gif \n",
    "        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2BGR)\n",
    "        overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "        stack = np.hstack((resized_frame, overlay))\n",
    "        # cv2.imshow(\"stacked\", stack)\n",
    "        image_lst.append(stack)\n",
    "\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(frame_rate) & 0xFF == ord('q'): #original waitkey is 25\n",
    "            break\n",
    "    \n",
    "    #Break out of loop if video is done\n",
    "    else:\n",
    "        break  \n",
    "\n",
    "vc.release() #Release the video capture object\n",
    "\n",
    "# Close window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('Outputs/V1_video.gif', image_lst, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('clarius')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9962539669d5dbe9522d46f218cca01fd3b7ad23018b1c5959dcfe17c72706ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
