{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "tensorflow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import imutils \n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "tf.__version__\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "import skimage.feature\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#check if tensorflow gpu is being used\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bbox(img,bbox_image):\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        \n",
    "        # # Debugging statements\n",
    "        # if area > 1:\n",
    "        #     print(\"Area of contour is: {}\".format(area))\n",
    "        \n",
    "        areaMin = 15\n",
    "        areaMax = 100\n",
    "        if area > areaMin and area < areaMax:\n",
    "            M = cv2.moments(cnt)\n",
    "            if M['m00'] != 0:\n",
    "                cx = int(M['m10']/M['m00'])\n",
    "                cy = int(M['m01']/M['m00'])\n",
    "            else:\n",
    "                cx = 0\n",
    "                cy = 0\n",
    "            print(cx, cy)\n",
    "            # cv2.drawContours(bbox_image, cnt, -1, (255, 0, 255), 7)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            # print(len(approx))\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(bbox_image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "            # cv2.circle(bbox_image, (cx, cy), 7, (0,255,0), -1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V3.1 - Threshold Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videos to choose from\n",
    "NeedleViz_path1 = 'Data/edited data/102622_Water.mp4'\n",
    "NeedleViz_path2 = 'Data/edited data/102822_Water.mp4'\n",
    "NeedleViz_oilAndLatex = 'Data/edited data/oil and latex/capture_5_2022-11-12T16-56-03.mp4'\n",
    "NeedleViz_gelAndLatex = 'Data/edited data/ultrasound gel and latex/capture_4_2022-11-12T17-33-19.mp4'\n",
    "NeedleViz_clarius1 = 'Data/edited data/clarius_FinalPrototype_needlejustWater.mp4'\n",
    "NeedleViz_clarius2 = 'Data/edited data/clarius_FinalPrototype_needlejustWater2.mp4'\n",
    "NeedleViz_clarius3 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid.mp4'\n",
    "NeedleViz_clarius4 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid2.mp4'\n",
    "NeedleViz_clarius5 = 'Data/edited data/clarius_FinalPrototype_needleWithSolid3.mp4'\n",
    "\n",
    "\n",
    "\n",
    "#control playback speed\n",
    "frame_rate = 30\n",
    "\n",
    "# vc = cv2.VideoCapture(0) #opens camera\n",
    "vc = cv2.VideoCapture(NeedleViz_clarius5)\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=10) #pretty good: (100,200)\n",
    "\n",
    "frameWidth = 440\n",
    "frameHeight = 440\n",
    "vc.set(3, frameWidth)\n",
    "vc.set(4, frameHeight)\n",
    "\n",
    "size = (frameWidth, frameHeight)\n",
    "\n",
    "#Preparing to create output videos\n",
    "image_lst = []\n",
    "\n",
    "if (vc.isOpened()== False): \n",
    "  print(\"Error opening video  file\")\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    if rval == True:\n",
    "\n",
    "        #Initial Frame preprocessing\n",
    "        ##############################################################\n",
    "        resized_frame = cv2.resize(frame, (frameWidth,frameHeight))\n",
    "        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "        ##############################################################\n",
    "\n",
    "\n",
    "        #Achieving desired region of interest within Raw Frame\n",
    "        ##############################################################\n",
    "        row_start = 140 #previously 94\n",
    "        row_end = 348\n",
    "        col_start = 195 #previously 166\n",
    "        col_end = 235 #previously 275\n",
    "\n",
    "        ROI_frame = resized_frame[row_start:row_end, col_start:col_end] #old one was [94:348, 166:275]\n",
    "        ROI_image = np.zeros_like(resized_frame)\n",
    "        x = row_start \n",
    "        y = col_start \n",
    "        for i in range(0, row_end-row_start):\n",
    "            for j in range(0, col_end-col_start):\n",
    "                if ROI_frame[i][j] != 0:\n",
    "                    ROI_image[x + i, y + j] = ROI_frame[i, j]\n",
    "        ############################################################## \n",
    "      \n",
    "        #Applying Combination Filters\n",
    "        #############################################################\n",
    "        \n",
    "        ### THRESHOLDING ###\n",
    "        thresh = cv2.threshold(ROI_image, 90, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        ### BASIC MORPHOLOGICAL OPERATIONS ###\n",
    "        # dilate = cv2.dilate(thresh, None, iterations=1)\n",
    "        # erode = cv2.erode(dilate, None, iterations=1)\n",
    "        # dilate_2 = cv2.dilate(erode, None, iterations=1)\n",
    "\n",
    "        \n",
    "        ### ADVANCED MORPHOLIGICAL OPERATIONS ###\n",
    "        skel_image = thresh.copy()\n",
    "\n",
    "        # Step 1: Create an empty skeleton\n",
    "        size = np.size(skel_image)\n",
    "        skel = np.zeros(skel_image.shape, np.uint8)\n",
    "\n",
    "        # Get a Cross Shaped Kernel\n",
    "        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "\n",
    "        #Step 2: Open the image\n",
    "        open = cv2.morphologyEx(skel_image, cv2.MORPH_OPEN, element)\n",
    "        #Step 3: Substract open from the original image\n",
    "        temp = cv2.subtract(skel_image, open)\n",
    "        #Step 4: Erode the original image and refine the skeleton\n",
    "        eroded = cv2.erode(skel_image, element)\n",
    "        skel = cv2.bitwise_or(skel_image,temp)\n",
    "        skel_image = eroded.copy()\n",
    "        #############################################################\n",
    "        \n",
    "        #Applying Edge and Bounding box detection\n",
    "        #############################################################\n",
    "        canny = cv2.Canny(skel_image, 73,200)\n",
    "        bbox = resized_frame.copy()\n",
    "        # detect_bbox(canny,bbox)\n",
    "        #############################################################\n",
    "\n",
    "        #Applying Paper Algorithm Filters\n",
    "        #############################################################\n",
    "        # gabor_filter = cv2.getGaborKernel((6,6), sigma=0.5, theta=0, lambd=0.5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "        gabor_filter = cv2.getGaborKernel((3,3), sigma=0.95, theta=0, lambd=5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "        # gabor_filter = cv2.getGaborKernel((3,3), sigma=0.5, theta=0, lambd=30, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "\n",
    "        gabor_output = cv2.filter2D(ROI_image, -1, gabor_filter)\n",
    "\n",
    "        #Binarized image is divided into grids for needle axis localization.\n",
    "        # - Median filter\n",
    "        median_filter = cv2.medianBlur(gabor_output, 7)\n",
    "        # - automatic thresholding\n",
    "        threshold = cv2.threshold(median_filter, 250, 255, cv2.THRESH_BINARY)[1]\n",
    "        # - morphological operations\n",
    "        element = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        eroded = cv2.erode(threshold, element)\n",
    "        dilated = cv2.dilate(eroded, element)\n",
    "        #############################################################\n",
    "        \n",
    "        #Hough Line Transforms\n",
    "        #############################################################\n",
    "        lines = cv2.HoughLinesP(dilated, rho=6, theta=np.pi / 2, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "\n",
    "        overlay_image = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        houghline = overlay_image.copy()\n",
    "\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                \n",
    "                # print(line)\n",
    "                # print(line[0][0])\n",
    "                # Start coordinate, here (0, 0)\n",
    "                # represents the top left corner of image\n",
    "                start_point = (line[0][0], line[0][1])\n",
    "                \n",
    "                # End coordinate, here (250, 250)\n",
    "                # represents the bottom right corner of image\n",
    "                end_point = (line[0][2], line[0][3])\n",
    "                \n",
    "                # Green color in BGR\n",
    "                color = (0, 255, 0)\n",
    "                \n",
    "                # Line thickness of 9 px\n",
    "                thickness = 2\n",
    "                \n",
    "                # Using cv2.line() method\n",
    "                # Draw a diagonal green line with thickness of 9 px\n",
    "                cv2.line(houghline, start_point, end_point, color, thickness)\n",
    "        #############################################################\n",
    "        \n",
    "\n",
    "        #Overlaying segmentations onto B-mode image\n",
    "        #############################################################################################\n",
    "        # fgmaskV2_color = cv2.applyColorMap(bbox, cv2.COLORMAP_INFERNO)\n",
    "        # resized_frame_revert = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2RGB)\n",
    "        # overlay = cv2.addWeighted(resized_frame_revert, 0.5, fgmaskV2_color, 0.5, 1.0)\n",
    "        # cv2.imshow(\"Bmode Overlay\", overlay)\n",
    "        ###########################################################################################\n",
    "\n",
    "        # Debugging Statements\n",
    "        cv2.imshow('normal frame', resized_frame)\n",
    "        cv2.imshow('ROI frame', ROI_image)\n",
    "        # cv2.imshow('thresholding', thresh)\n",
    "        # cv2.imshow('Morphological Operations', skel_image)\n",
    "        # cv2.imshow('Canny Edge Detection', canny)\n",
    "        # cv2.imshow('Object Detection', bbox)\n",
    "        cv2.imshow('Paper Algorithm', dilated)\n",
    "        cv2.imshow('Hough Line Transform', houghline)\n",
    "        \n",
    "        #Saving comparison frames as gif \n",
    "        # resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2BGR)\n",
    "        # overlay = cv2.cvtColor(houghline, cv2.COLOR_RGB2BGR)\n",
    "        # stack = np.hstack((resized_frame, overlay))\n",
    "        # cv2.imshow(\"stacked\", stack)\n",
    "        # image_lst.append(stack)\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(frame_rate) & 0xFF == ord('q'): #original waitkey is 25\n",
    "            break\n",
    "    \n",
    "    #Break out of loop if video is done\n",
    "    else:\n",
    "        break  \n",
    "\n",
    "vc.release() #Release the video capture object\n",
    "\n",
    "# Close window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Video as GIF\n",
    "imageio.mimsave('Outputs/V3_2_video.gif', image_lst, fps=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Frame Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameList = []\n",
    "\n",
    "vc = cv2.VideoCapture(NeedleViz_clarius1)\n",
    "\n",
    "if (vc.isOpened()== False): \n",
    "  print(\"Error opening video  file\")\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    rval, frame = vc.read()\n",
    "    \n",
    "    if rval == True:\n",
    "      frameList.append(frame)\n",
    "        \n",
    "    #Break out of loop if video is done\n",
    "    else:\n",
    "        break  \n",
    "\n",
    "vc.release() #Release the video capture object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = frameList[30]\n",
    "image_refined = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROI FRAME EXTRACTION ###\n",
    "\n",
    "size = (440, 440)\n",
    "\n",
    "#Initial Frame preprocessing\n",
    "resized_frame = cv2.resize(image, size)\n",
    "resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(resized_frame)\n",
    "\n",
    "#Achieving desired region of interest within Raw Frame\n",
    "row_start = 140 #previously 94\n",
    "row_end = 348\n",
    "col_start = 195 #previously 166\n",
    "col_end = 235 #previously 275\n",
    "\n",
    "ROI_frame = resized_frame[row_start:row_end, col_start:col_end] #old one was [94:348, 166:275]\n",
    "ROI_image = np.zeros_like(resized_frame)\n",
    "x = row_start \n",
    "y = col_start \n",
    "for i in range(0, row_end-row_start):\n",
    "    for j in range(0, col_end-col_start):\n",
    "        if ROI_frame[i][j] != 0:\n",
    "            ROI_image[x + i, y + j] = ROI_frame[i, j]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ROI_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLURRING AND THRESHOLDING ###\n",
    "\n",
    "thresh = cv2.threshold(ROI_image, 90, 255, cv2.THRESH_BINARY)[1]\n",
    "plt.figure()\n",
    "plt.imshow(thresh)\n",
    "\n",
    "# adapt_thresh = cv2.adaptiveThreshold(thresh, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(adapt_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MORPHOLOGICAL OPERATIONS ###\n",
    "dilate = cv2.dilate(thresh, None, iterations=2)\n",
    "erode = cv2.erode(dilate, None, iterations=2)\n",
    "dilate_2 = cv2.dilate(erode, None, iterations=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(dilate_2)\n",
    "\n",
    "#Creating skeleton -> https://medium.com/analytics-vidhya/skeletonization-in-python-using-opencv-b7fa16867331 \n",
    "\n",
    "skel_image = thresh.copy()\n",
    "\n",
    "# Step 1: Create an empty skeleton\n",
    "size = np.size(skel_image)\n",
    "skel = np.zeros(skel_image.shape, np.uint8)\n",
    "\n",
    "# Get a Cross Shaped Kernel\n",
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "\n",
    "count = 0\n",
    "# Repeat steps 2-4\n",
    "while True:\n",
    "    #Step 2: Open the image\n",
    "    open = cv2.morphologyEx(skel_image, cv2.MORPH_OPEN, element)\n",
    "    #Step 3: Substract open from the original image\n",
    "    temp = cv2.subtract(skel_image, open)\n",
    "    #Step 4: Erode the original image and refine the skeleton\n",
    "    eroded = cv2.erode(skel_image, element)\n",
    "    skel = cv2.bitwise_or(skel_image,temp)\n",
    "    skel_image = eroded.copy()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(skel_image)\n",
    "    count += 1\n",
    "    # Step 5: If there are no white pixels left ie.. the image has been completely eroded, quit the loop\n",
    "    if count == 3:\n",
    "        break\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(skel_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CANNY EDGE DETECTION ###\n",
    "canny = cv2.Canny(skel_image, 73,200)\n",
    "\n",
    "plt.imshow(canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = resized_frame.copy()\n",
    "detect_bbox(canny,bbox)\n",
    "plt.imshow(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm based on Paper: https://ris.utwente.nl/ws/portalfiles/portal/268816902/elk_28_5_37_1912_181.pdf \n",
    "\n",
    "#Raw Image\n",
    "raw_image = ROI_image.copy()\n",
    "# plt.figure()\n",
    "# plt.imshow(raw_image)\n",
    "\n",
    "#Gabor Filter at angle 0\n",
    "\n",
    "gabor_filter = cv2.getGaborKernel((3,3), sigma=0.95, theta=0, lambd=5, gamma=0.8, psi=0, ktype=cv2.CV_32F)\n",
    "# gabor_filter = cv2.getGaborKernel((3,3), sigma=10, theta=0, lambd=30, gamma=0.25, psi=0, ktype=cv2.CV_32F)\n",
    "# plt.figure()\n",
    "# plt.imshow(gabor_filter)\n",
    "gabor_output = cv2.filter2D(raw_image, -1, gabor_filter)\n",
    "# plt.figure()\n",
    "# plt.imshow(gabor_output)\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(131)\n",
    "plt.axis('off')\n",
    "plt.title('image')\n",
    "plt.imshow(raw_image, cmap='gray')\n",
    "plt.subplot(132)\n",
    "plt.title('kernel')\n",
    "plt.imshow(gabor_filter, cmap='gray')\n",
    "plt.subplot(133)\n",
    "plt.axis('off')\n",
    "plt.title('filtered')\n",
    "plt.imshow(gabor_output, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Binarized image is divided into grids for needle axis localization.\n",
    "# - Median filter\n",
    "median_filter = cv2.medianBlur(gabor_output, 7)\n",
    "plt.figure()\n",
    "plt.imshow(median_filter)\n",
    "# - automatic thresholding\n",
    "threshold = cv2.threshold(median_filter, 250, 255, cv2.THRESH_BINARY)[1]\n",
    "# - morphological operations\n",
    "element = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "eroded = cv2.erode(threshold, element)\n",
    "dilated = cv2.dilate(eroded, element)\n",
    "plt.figure()\n",
    "plt.imshow(dilated)\n",
    "\n",
    "#needle tip estimation\n",
    "\n",
    "\n",
    "# Connected components\n",
    "\n",
    "# largest connected component is chosen as the needle\n",
    "\n",
    "#  Needle axis is localized by applying RANSAC line fitting to each grid\n",
    "\n",
    "# The needle tip is estimated using probability mapping method\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(dilated, rho=6, theta=np.pi / 60, threshold=160, lines=np.array([]), minLineLength=40, maxLineGap=4)\n",
    "\n",
    "overlay_image = cv2.cvtColor(resized_frame, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "houghline = overlay_image.copy()\n",
    "\n",
    "for line in lines:\n",
    "    # print(line)\n",
    "    # print(line[0][0])\n",
    "    # Start coordinate, here (0, 0)\n",
    "    # represents the top left corner of image\n",
    "    start_point = (line[0][0], line[0][1])\n",
    "    \n",
    "    # End coordinate, here (250, 250)\n",
    "    # represents the bottom right corner of image\n",
    "    end_point = (line[0][2], line[0][3])\n",
    "    \n",
    "    # Green color in BGR\n",
    "    color = (0, 255, 0)\n",
    "    \n",
    "    # Line thickness of 9 px\n",
    "    thickness = 2\n",
    "    \n",
    "    # Using cv2.line() method\n",
    "    # Draw a diagonal green line with thickness of 9 px\n",
    "    cv2.line(houghline, start_point, end_point, color, thickness)\n",
    "\n",
    "plt.imshow(houghline)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('clarius')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9962539669d5dbe9522d46f218cca01fd3b7ad23018b1c5959dcfe17c72706ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
